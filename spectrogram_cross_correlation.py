#!/usr/bin/env python3
"""
Spectrogram Cross-Correlation (SPCC) Analysis
Compares visual similarity of spectrograms to assess vocal consistency
and detect potential individual variation
"""

import pandas as pd
import numpy as np
import librosa
import matplotlib.pyplot as plt
from pathlib import Path
from scipy.signal import correlate2d
from scipy.stats import zscore
import warnings
warnings.filterwarnings('ignore')

print("=" * 80)
print("ðŸ”¬ SPECTROGRAM CROSS-CORRELATION ANALYSIS")
print("=" * 80)
print()

# Load detections
df = pd.read_csv('results/all_detections_with_weather.csv')
audio_dir = Path('results/audio_clips_enhanced')

print(f"Dataset: {len(df)} detections")
print()

# ============================================================================
# SPECTROGRAM GENERATION PARAMETERS
# ============================================================================

def generate_spectrogram(audio_path, sr=22050, n_fft=2048, hop_length=512):
    """Generate log-power spectrogram"""
    try:
        y, sr = librosa.load(audio_path, sr=sr)

        # Generate spectrogram
        S = librosa.stft(y, n_fft=n_fft, hop_length=hop_length)
        S_db = librosa.amplitude_to_db(np.abs(S), ref=np.max)

        return S_db, sr
    except Exception as e:
        return None, None

def normalized_cross_correlation(spec1, spec2):
    """
    Calculate normalized 2D cross-correlation between two spectrograms
    Returns correlation coefficient (0-1)
    """
    # Ensure same shape (pad or crop)
    min_time = min(spec1.shape[1], spec2.shape[1])
    spec1 = spec1[:, :min_time]
    spec2 = spec2[:, :min_time]

    # Normalize by z-score
    spec1_norm = zscore(spec1.flatten())
    spec2_norm = zscore(spec2.flatten())

    # Calculate correlation coefficient
    correlation = np.corrcoef(spec1_norm, spec2_norm)[0, 1]

    return correlation

def spectrogram_similarity_matrix(spectrograms):
    """
    Calculate pairwise similarity matrix for all spectrograms
    """
    n = len(spectrograms)
    similarity_matrix = np.zeros((n, n))

    for i in range(n):
        for j in range(i, n):
            if spectrograms[i] is not None and spectrograms[j] is not None:
                corr = normalized_cross_correlation(spectrograms[i], spectrograms[j])
                similarity_matrix[i, j] = corr
                similarity_matrix[j, i] = corr
            else:
                similarity_matrix[i, j] = 0
                similarity_matrix[j, i] = 0

    return similarity_matrix

# ============================================================================
# ANALYZE TOP SPECIES WITH MULTIPLE EXAMPLES
# ============================================================================

print("=" * 80)
print("VOCAL CONSISTENCY ANALYSIS (SPCC)")
print("=" * 80)
print()

# Focus on species with most detections
target_species = ['Graylag Goose', 'Spotted Crake', 'Great Snipe', 'Pink-footed Goose']

results = []

for species in target_species:
    print(f"Analyzing: {species}")
    print("-" * 80)

    species_df = df[df['common_name'] == species].nlargest(20, 'confidence')

    if len(species_df) < 5:
        print(f"  Insufficient data (n={len(species_df)})")
        print()
        continue

    # Load spectrograms
    spectrograms = []
    metadata = []

    for idx, row in species_df.iterrows():
        filename_stem = Path(row['filename']).stem
        start_s = row['start_s']
        species_name = row['common_name'].replace(' ', '_').replace('/', '-')

        pattern = f"{filename_stem}_{species_name}_{int(start_s)}s_*.wav"
        matching_files = list(audio_dir.glob(pattern))

        if not matching_files:
            continue

        spec, sr = generate_spectrogram(matching_files[0])

        if spec is not None:
            spectrograms.append(spec)
            metadata.append({
                'species': species,
                'filename': row['filename'],
                'start_s': start_s,
                'confidence': row['confidence']
            })

    if len(spectrograms) < 5:
        print(f"  Could not load sufficient spectrograms (n={len(spectrograms)})")
        print()
        continue

    print(f"  Loaded {len(spectrograms)} spectrograms")

    # Calculate similarity matrix
    similarity_matrix = spectrogram_similarity_matrix(spectrograms)

    # Calculate statistics
    # Extract upper triangle (excluding diagonal)
    upper_tri_indices = np.triu_indices_from(similarity_matrix, k=1)
    similarities = similarity_matrix[upper_tri_indices]

    mean_similarity = np.mean(similarities)
    std_similarity = np.std(similarities)
    min_similarity = np.min(similarities)
    max_similarity = np.max(similarities)

    print(f"  Mean similarity:  {mean_similarity:.3f} Â± {std_similarity:.3f}")
    print(f"  Range:            {min_similarity:.3f} - {max_similarity:.3f}")

    # Vocal consistency interpretation
    if mean_similarity > 0.90:
        consistency = "VERY HIGH (stereotyped calls)"
    elif mean_similarity > 0.75:
        consistency = "HIGH (consistent calls)"
    elif mean_similarity > 0.60:
        consistency = "MODERATE (some variation)"
    else:
        consistency = "LOW (high variation)"

    print(f"  Vocal consistency: {consistency}")

    # Check for clustering (potential individuals)
    # If there are distinct clusters with high within-cluster similarity
    # and low between-cluster similarity, suggests multiple individuals

    # Find most similar and most different pairs
    similarities_sorted = np.sort(similarities)
    top_10_similar = similarities_sorted[-10:]
    bottom_10_similar = similarities_sorted[:10]

    print(f"  Top 10% similarity:    {np.mean(top_10_similar):.3f}")
    print(f"  Bottom 10% similarity: {np.mean(bottom_10_similar):.3f}")
    print(f"  Separation:            {np.mean(top_10_similar) - np.mean(bottom_10_similar):.3f}")

    # If separation > 0.15, suggests potential individual variation
    if np.mean(top_10_similar) - np.mean(bottom_10_similar) > 0.15:
        print(f"  â†’ Potential individual variation detected")
    else:
        print(f"  â†’ Calls highly uniform (likely stereotyped species vocalization)")

    print()

    results.append({
        'species': species,
        'n_calls': len(spectrograms),
        'mean_similarity': mean_similarity,
        'std_similarity': std_similarity,
        'min_similarity': min_similarity,
        'max_similarity': max_similarity,
        'top_10_pct': np.mean(top_10_similar),
        'bottom_10_pct': np.mean(bottom_10_similar),
        'separation': np.mean(top_10_similar) - np.mean(bottom_10_similar),
        'consistency': consistency
    })

# ============================================================================
# COMPARISON: SPCC vs MFCC
# ============================================================================

print("=" * 80)
print("COMPARISON: SPECTROGRAM vs MFCC SIMILARITY")
print("=" * 80)
print()

print("Key Differences:")
print("-" * 80)
print()
print("MFCC (Mel-Frequency Cepstral Coefficients):")
print("  â€¢ Compact representation (13 coefficients)")
print("  â€¢ Captures overall spectral envelope")
print("  â€¢ Fast to compute")
print("  â€¢ May miss fine-grained temporal structure")
print("  â€¢ Result: 0.97-1.00 similarity (very high)")
print()
print("SPCC (Spectrogram Cross-Correlation):")
print("  â€¢ Full 2D time-frequency representation")
print("  â€¢ Captures fine temporal and spectral details")
print("  â€¢ Slower to compute")
print("  â€¢ More sensitive to individual variation")

if results:
    spcc_mean = np.mean([r['mean_similarity'] for r in results])
    print(f"  â€¢ Result: {spcc_mean:.3f} average similarity")
    print()
    print("INTERPRETATION:")
    print("-" * 80)
    if spcc_mean > 0.85:
        print("  âœ“ Both methods show high similarity")
        print("  â†’ Calls are genuinely stereotyped at species level")
        print("  â†’ Individual recognition would require:")
        print("    â€¢ Spatial array (separate overlapping calls)")
        print("    â€¢ Known individuals (ground truth)")
        print("    â€¢ Longer recording sessions per individual")
    else:
        print("  âœ“ SPCC reveals more variation than MFCC")
        print("  â†’ Individual variation may exist")
        print("  â†’ Would need validation with known individuals")
print()

# ============================================================================
# SAVE RESULTS
# ============================================================================

if results:
    results_df = pd.DataFrame(results)
    results_df.to_csv('results/spectrogram_cross_correlation.csv', index=False)
    print("âœ… Saved results: results/spectrogram_cross_correlation.csv")
    print()

print("=" * 80)
print("SCIENTIFIC CONCLUSION")
print("=" * 80)
print()
print("Without known individuals, we CANNOT claim individual recognition.")
print()
print("What we CAN claim:")
print("  â€¢ High vocal consistency within species (stereotyped calls)")
print("  â€¢ Potential for individual variation (requires validation)")
print("  â€¢ SPCC provides more detailed similarity assessment than MFCC")
print()
print("Next steps for individual recognition:")
print("  1. Deploy microphone array (3+ recorders)")
print("  2. Capture/band individuals â†’ create reference library")
print("  3. Validate clustering against known identities")
print("  4. Measure accuracy with cross-validation")
print()

print("=" * 80)
print("âœ… SPECTROGRAM CROSS-CORRELATION COMPLETE")
print("=" * 80)
print()
